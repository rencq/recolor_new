{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20dd2245-3178-4d98-b1f0-6e2a3a8d6105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import torch\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "try:\n",
    "    import piplite\n",
    "    await piplite.install(['ipywidgets'])\n",
    "except ImportError:\n",
    "    pass\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efdadb22-beb4-4bb4-9738-842e926683a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from engine.trainer import Trainer\n",
    "from engine.eval import evaluation_path\n",
    "from engine.get_point_cloud import write_point_cloud,read_point_cloud\n",
    "from data import dataset_dict\n",
    "from utils.opt import config_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b453828b-8334-4cc4-8e59-5ad4ca21da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_redirect = [\n",
    "    # option name, path in the config, redirected path\n",
    "    ('palette_path', './data_palette', '../data_palette')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b8ab45c-fc4d-4470-b65e-6d69386d39d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = '../logs/chair'\n",
    "ckpt_path = None\n",
    "out_dir = os.path.join(run_dir,'demo_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#读取数据\n",
    "def read_data(dataset_type='train'):\n",
    "    parser = config_parser()\n",
    "    config_path = os.path.join(run_dir,'args.txt')\n",
    "\n",
    "    if os.path.exists(config_path):\n",
    "        with open(config_path,'r') as f:\n",
    "            args,remainings = parser.parse_known_args(args=[],config_file_contents=f.read())\n",
    "\n",
    "            if ckpt_path is not None:\n",
    "                setattr(args,'ckpt',ckpt_path)\n",
    "\n",
    "            for entry in path_redirect:\n",
    "                setattr(args,entry[0],getattr(args,entry[0]).replace(entry[1],entry[2]))\n",
    "\n",
    "            print(\"Args loaded:\", args)\n",
    "    else:\n",
    "        print(f\"ERROR : cannot read args in {run_dir}.\")\n",
    "    print()\n",
    "\n",
    "    dataset = dataset_dict[args.dataset_name]\n",
    "    # train_dataset\n",
    "    train_dataset = dataset(args.datadir,split='train',downsample=args.downsample_train * 2.,is_stack=True)\n",
    "    # test_dataset\n",
    "    test_dataset = dataset(args.datadir,split='test',downsample=args.downsample_test*2., is_stack=True)\n",
    "    if dataset_type =='train':\n",
    "        return args,train_dataset\n",
    "    else:\n",
    "        return args,test_dataset\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from utils.color_decomposition import color_decomposition\n",
    "\n",
    "def plot_color_decomposition(ds_test_dataset,rgbs,palette_rgb,plot_palette_color_idx=0,dataset=None,fg=None):\n",
    "    w, h = ds_test_dataset.img_wh\n",
    "    # palette_rgb = palette_rgb.clip(0.,1.)\n",
    "    rgbs = torch.tensor(rgbs/255)\n",
    "    rgbs = torch.reshape(rgbs,(-1,3))\n",
    "    palette_rgb = torch.tensor(palette_rgb)\n",
    "    palette_number = palette_rgb.shape[0]\n",
    "    color_deco = color_decomposition(rgbs,palette_rgb) # bs * h * w\n",
    "    # print(rgbs)\n",
    "    print(palette_rgb)\n",
    "    plot_palette_color =  0\n",
    "    true_idx = (color_deco != plot_palette_color) # bs * 1\n",
    "\n",
    "    if dataset is not None and dataset.white_bg and fg is not None:\n",
    "        all_rgb_cp = dataset.all_rgbs.clone().cpu()\n",
    "        all_rgb_cp_original = dataset.all_rgbs.clone().cpu()\n",
    "        fg[fg==True] = true_idx\n",
    "\n",
    "        all_rgb_cp[fg] = 1.\n",
    "    else:\n",
    "        all_rgb_cp = torch.clone(rgbs)\n",
    "        all_rgb_cp_original = torch.clone(rgbs)\n",
    "        all_rgb_cp[true_idx] = 1.\n",
    "\n",
    "\n",
    "\n",
    "    all_rgb_maps = torch.reshape(all_rgb_cp,(-1, h, w, 3))\n",
    "    # print(all_rgb_maps)\n",
    "    all_rgb_cp_original = torch.reshape(all_rgb_cp_original,(-1,h,w,3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig,axes = plt.subplots(1,2)\n",
    "    axes[0].imshow(all_rgb_maps[plot_palette_color_idx].clone().numpy())\n",
    "    axes[1].imshow(all_rgb_cp_original[plot_palette_color_idx].clone().numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def write_pointcloud(dataset_type='train',):\n",
    "\n",
    "    #读取数据\n",
    "    args,dataset = read_data(dataset_type=dataset_type,)\n",
    "\n",
    "    print(\"Initializing trainer and model...\")\n",
    "    ckpt_dir = os.path.join(run_dir,\"checkpoints\")\n",
    "    tb_dir = os.path.join(run_dir,\"tensorboard\")\n",
    "\n",
    "    trainer = Trainer(args,run_dir,ckpt_dir, tb_dir)\n",
    "\n",
    "    model = trainer.build_network()\n",
    "    model.eval()\n",
    "    print()\n",
    "\n",
    "    #调色板提取\n",
    "    palette_prior = trainer.palette_prior.detach().cpu().numpy()\n",
    "    palette = model.renderModule.palette.get_palette_array().detach().cpu().numpy()\n",
    "\n",
    "    print(\"==============*****************==================\")\n",
    "    write_point_cloud(dataset, model, args, trainer.renderer, savePath=None, N_vis=5, N_samples=-1, white_bg=False,\n",
    "               ndc_ray=False, palette=palette, new_palette=None,device='cuda',filename=None)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args loaded: Namespace(L1_weight_inital=8e-05, L1_weight_rest=4e-05, N_vis=5, N_voxel_final=27000000, N_voxel_init=2097156, Ortho_weight=0.0, Plt_bd_weight=1.0, Plt_opaque_conv_weight=0.0, Plt_opaque_sps_weight=0.001, TV_weight_app=0.0, TV_weight_density=0.0, alpha_mask_thre=0.0001, basedir='./logs', batch_size=4096, ckpt=None, config='configs/chair.txt', data_dim_color=27, datadir='/home/ubuntu/Rencq/nerf_data/nerf_synthetic/chair', dataset_name='blender', density_shift=-10.0, distance_scale=25.0, downsample_test=1.0, downsample_train=1.0, expname='chair', export_mesh=0, fea2denseAct='softplus', fea_pe=2, featureC=128, learn_palette=True, lindisp=False, lr_basis=0.001, lr_decay_iters=-1, lr_decay_target_ratio=0.1, lr_init=0.02, lr_upsample_reset=1, model_name='PaletteTensorVM', nSamples=1000000, n_iters=30000, n_lamb_sh=[48, 48, 48], n_lamb_sigma=[16, 16, 16], ndc_ray=0, no_reload=0, palette_init='userinput', palette_path='../data_palette/chair/rgb_palette.npy', perturb=1.0, pos_pe=6, progress_refresh_every=10, render_only=0, render_path=0, render_test=1, render_train=0, rm_weight_mask_thre=0.0001, shadingMode='PLT_AlphaBlend', soft_l0_sharpness=24.0, step_ratio=0.5, update_AlphaMask_list=[2000, 3000, 4000], upsamp_list=[2000, 3000, 4000, 5500, 7000], view_pe=2, vis_every=10000, white_bkgd=False)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data train (100): 100%|██████████| 100/100 [00:03<00:00, 32.85it/s]\n",
      "Loading data test (200): 100%|██████████| 200/200 [00:06<00:00, 33.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing trainer and model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data train (100): 100%|██████████| 100/100 [00:01<00:00, 57.25it/s]\n",
      "Loading data test (200): 100%|██████████| 200/200 [00:03<00:00, 56.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trainer init] aabb [[-1.5, -1.5, -1.5], [1.5, 1.5, 1.5]]\n",
      "[trainer init] num of render samples 443\n",
      "[trainer init] palette shape torch.Size([4, 3])\n",
      "[update_stepSize] aabb tensor([-0.7441, -0.7205, -1.0276,  0.6732,  0.7441,  1.0748], device='cuda:0')\n",
      "[update_stepSize] grid size [260, 268, 385]\n",
      "[update_stepSize] sampling step size:  tensor(0.0027, device='cuda:0')\n",
      "[update_stepSize] sampling number:  1070\n",
      "[init_render_func] shadingMode=PLT_AlphaBlend pos_pe=6 view_pe=2 fea_pe=2 learn_palette=True palette_init=userinput\n",
      "[TensorBase init] renderModule: PLTRender(\n",
      "  (palette): FreeformPalette()\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=150, out_features=128, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (4): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "[TensorBase init] render buffer layout: [RenderBufferProp(name='rgb', len=3, detach_weight=False, type='RGB'), RenderBufferProp(name='opaque', len=4, detach_weight=True, type=''), RenderBufferProp(name='sparsity_norm', len=1, detach_weight=False, type='')]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2d877e5a6f3473dab1e65b9e0f185bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration ===========>    0%|          | 0/5 [00:00<?, ?it/s] times\n",
      " ================>  0  times\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#写点云\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mwrite_pointcloud\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[7], line 20\u001B[0m, in \u001B[0;36mwrite_pointcloud\u001B[0;34m(dataset_type)\u001B[0m\n\u001B[1;32m     17\u001B[0m palette_prior \u001B[38;5;241m=\u001B[39m trainer\u001B[38;5;241m.\u001B[39mpalette_prior\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m     18\u001B[0m palette \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mrenderModule\u001B[38;5;241m.\u001B[39mpalette\u001B[38;5;241m.\u001B[39mget_palette_array()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m---> 20\u001B[0m \u001B[43mwrite_point_cloud\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrenderer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msavePath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mN_vis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mN_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhite_bg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m           \u001B[49m\u001B[43mndc_ray\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpalette\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpalette\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_palette\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/recolor_new/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[0;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Rencq/RecolorNeRF/tools/../engine/get_point_cloud.py:34\u001B[0m, in \u001B[0;36mwrite_point_cloud\u001B[0;34m(test_dataset, tensorf, args, renderer, savePath, N_vis, N_samples, white_bg, ndc_ray, palette, new_palette, device, filename)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# W, H = test_dataset.img_wh\u001B[39;00m\n\u001B[1;32m     32\u001B[0m rays \u001B[38;5;241m=\u001B[39m samples\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, samples\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m---> 34\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mrenderer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrays\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensorf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4096\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mN_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mN_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mndc_ray\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mndc_ray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhite_bg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwhite_bg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[43m               \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[43m               \u001B[49m\u001B[43mret_opaque_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpalette\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpalette\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_palette\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnew_palette\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m depth_map \u001B[38;5;241m=\u001B[39m res[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdepth_map\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     40\u001B[0m point_cloud \u001B[38;5;241m=\u001B[39m rays[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m,:\u001B[38;5;241m3\u001B[39m] \u001B[38;5;241m+\u001B[39m rays[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m,\u001B[38;5;241m3\u001B[39m:\u001B[38;5;241m6\u001B[39m] \u001B[38;5;241m*\u001B[39m depth_map\n",
      "File \u001B[0;32m~/Rencq/RecolorNeRF/tools/../utils/render.py:30\u001B[0m, in \u001B[0;36mchunkify_render\u001B[0;34m(rays, tensorf, chunk, N_samples, ndc_ray, white_bg, is_train, device, **kwargs)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk_idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(N_rays_all \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m chunk \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mint\u001B[39m(N_rays_all \u001B[38;5;241m%\u001B[39m chunk \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m)):  \u001B[38;5;66;03m#批量渲染\u001B[39;00m\n\u001B[1;32m     28\u001B[0m     rays_chunk \u001B[38;5;241m=\u001B[39m rays[chunk_idx \u001B[38;5;241m*\u001B[39m chunk:(chunk_idx \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m*\u001B[39m chunk]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m---> 30\u001B[0m     res_dict \u001B[38;5;241m=\u001B[39m \u001B[43mtensorf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrays_chunk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhite_bg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwhite_bg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mndc_ray\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mndc_ray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mN_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mN_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m res_dict:\n\u001B[1;32m     33\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m ret:\n",
      "File \u001B[0;32m~/.conda/envs/recolor_new/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Rencq/RecolorNeRF/tools/../models/tensorBase.py:472\u001B[0m, in \u001B[0;36mTensorBase.forward\u001B[0;34m(self, rays_chunk, white_bg, is_train, ndc_ray, N_samples, **kwargs)\u001B[0m\n\u001B[1;32m    470\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m app_mask\u001B[38;5;241m.\u001B[39many():\n\u001B[1;32m    471\u001B[0m     app_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_appfeature(xyz_sampled[app_mask])\n\u001B[0;32m--> 472\u001B[0m     valid_render_bufs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrenderModule\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxyz_sampled\u001B[49m\u001B[43m[\u001B[49m\u001B[43mapp_mask\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mviewdirs\u001B[49m\u001B[43m[\u001B[49m\u001B[43mapp_mask\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mapp_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    473\u001B[0m     render_buf[app_mask] \u001B[38;5;241m=\u001B[39m valid_render_bufs\n\u001B[1;32m    475\u001B[0m ret \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[0;32m~/.conda/envs/recolor_new/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Rencq/RecolorNeRF/tools/../models/palette_tensoRF.py:82\u001B[0m, in \u001B[0;36mPLTRender.forward\u001B[0;34m(self, pts, viewdirs, features, is_train, **kwargs)\u001B[0m\n\u001B[1;32m     80\u001B[0m palette \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpalette\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_train \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpalette\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m kwargs:\n\u001B[0;32m---> 82\u001B[0m     palette \u001B[38;5;241m=\u001B[39m \u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpalette\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m(pts\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m     83\u001B[0m     new_palette \u001B[38;5;241m=\u001B[39m kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnew_palette\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(pts\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m     85\u001B[0m     \u001B[38;5;66;03m#调试  以50%的概率选择调色盘\u001B[39;00m\n\u001B[1;32m     86\u001B[0m     \u001B[38;5;66;03m# x = random.uniform(0,1)\u001B[39;00m\n\u001B[1;32m     87\u001B[0m     \u001B[38;5;66;03m# if(x<0.5):\u001B[39;00m\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;66;03m#     palette = palette\u001B[39;00m\n\u001B[1;32m     89\u001B[0m     \u001B[38;5;66;03m# else:\u001B[39;00m\n\u001B[1;32m     90\u001B[0m     \u001B[38;5;66;03m#     palette = new_palette\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "#写点云\n",
    "write_pointcloud()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "recolor_new",
   "language": "python",
   "display_name": "recolor_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
